#!/usr/bin/env python3
"""
å¡”ç½—ç‰Œç¿»è¯‘ç³»ç»Ÿé…ç½®æ–‡ä»¶
ç‹¬ç«‹é…ç½®ç®¡ç†ï¼Œä¸ä¾èµ–å¤–éƒ¨é…ç½®ã€‚
æ•æ„Ÿä¿¡æ¯ï¼ˆå¦‚ API Keyï¼‰é€šè¿‡ç¯å¢ƒå˜é‡æˆ– .env æ–‡ä»¶æ³¨å…¥ã€‚
"""

from __future__ import annotations

import os
from pathlib import Path
from typing import Any, Dict

from dotenv import load_dotenv


class TranslationConfig:
    """ç¿»è¯‘ç³»ç»Ÿé…ç½®ç±»"""

    def __init__(self) -> None:
        self.base_dir = Path(__file__).parent
        load_dotenv(self.base_dir.parent / ".env")
        self.config = self._load_config()
        self.validate()

    # ------------------------------------------------------------------
    # Helpers
    # ------------------------------------------------------------------
    def _env_str(self, key: str, default: str | None = None) -> str | None:
        value = os.getenv(key)
        return value if value not in (None, "") else default

    def _env_float(self, key: str, default: float) -> float:
        value = os.getenv(key)
        return float(value) if value not in (None, "") else default

    def _env_int(self, key: str, default: int) -> int:
        value = os.getenv(key)
        return int(value) if value not in (None, "") else default

    # ------------------------------------------------------------------
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½ç¿»è¯‘é…ç½®"""

        openai_api_key = self._env_str("TRANSLATION_OPENAI_API_KEY") or self._env_str("OPENAI_API_KEY")
        openai_base_url = self._env_str(
            "TRANSLATION_OPENAI_BASE_URL",
            self._env_str("OPENAI_BASE_URL", "https://api.openai.com/v1"),
        )
        openai_model = self._env_str("TRANSLATION_OPENAI_MODEL", self._env_str("OPENAI_MODEL_NAME", "gpt-4o-mini"))
        openai_temperature = self._env_float("TRANSLATION_OPENAI_TEMPERATURE", 0.3)
        openai_max_tokens = self._env_int("TRANSLATION_OPENAI_MAX_TOKENS", 2000)
        openai_timeout = self._env_int("TRANSLATION_OPENAI_TIMEOUT", 60)
        rate_limit_per_minute = self._env_int("TRANSLATION_RATE_LIMIT_PER_MINUTE", 60)
        batch_size = self._env_int("TRANSLATION_BATCH_SIZE", 10)

        return {
            # AI APIé…ç½®
            "ai_config": {
                "provider": "openai",
                "openai": {
                    "api_key": openai_api_key,
                    "base_url": openai_base_url,
                    "model": openai_model,
                    "temperature": openai_temperature,  # ç¨å¾®æé«˜æ¸©åº¦ä»¥è·å¾—æ›´å¥½çš„å“åº”
                    "max_tokens": openai_max_tokens,   # å¢åŠ tokené™åˆ¶
                    "timeout": openai_timeout,
                },
            },

            # æ•°æ®åº“é…ç½®
            "database": {
                "path": self.base_dir.parent / "data" / "tarot_config.db",
                "source_locale": "zh-CN",
                "target_locale": "en",
            },

            # è¾“å‡ºè·¯å¾„é…ç½®
            "paths": {
                "output_root": self.base_dir / "output",
                "raw_data_dir": self.base_dir / "output" / "database_raw",
                "translated_data_dir": self.base_dir / "output" / "database_translated",
                "prompts_dir": self.base_dir / "prompts",
                "glossary_file": self.base_dir / "translation_glossary.json",
            },

            # æ‰¹å¤„ç†é…ç½®
            "batch_config": {
                "batch_size": batch_size,
                "rate_limit_per_minute": rate_limit_per_minute,
                "max_retries": 3,
                "retry_delay": 2.0,
            },

            # ç¿»è¯‘è¡¨é…ç½®
            "tables": {
                "card": {
                    "source_file": "card_raw.json",
                    "target_file": "card_translated.json",
                    "prompt_file": "card_translation.txt",
                    "description": "å¡”ç½—ç‰ŒåŸºç¡€ä¿¡æ¯ç¿»è¯‘",
                },
                "spread": {
                    "source_file": "spread_raw.json",
                    "target_file": "spread_translated.json",
                    "prompt_file": "spread_translation.txt",
                    "description": "ç‰Œé˜µç¿»è¯‘",
                },
                "card_interpretation": {
                    "source_file": "card_interpretation_raw.json",
                    "target_file": "card_interpretation_translated.json",
                    "prompt_file": "interpretation_translation.txt",
                    "description": "å¡ç‰Œè§£è¯»ç¿»è¯‘",
                },
            },
        }

    def validate(self) -> None:
        """éªŒè¯é…ç½®å®Œæ•´æ€§"""
        required_sections = ["ai_config", "database", "paths", "batch_config", "tables"]

        for section in required_sections:
            if section not in self.config:
                raise ValueError(f"é…ç½®ç¼ºå°‘å¿…éœ€çš„èŠ‚: {section}")

        # éªŒè¯AIé…ç½®
        ai_config = self.config["ai_config"]
        if ai_config["provider"] == "openai":
            openai_config = ai_config.get("openai", {})
            required_openai_keys = ["api_key", "base_url", "model"]
            for key in required_openai_keys:
                if not openai_config.get(key):
                    raise ValueError(f"OpenAIé…ç½®ç¼ºå°‘å¿…éœ€çš„é”®: {key}")

        # éªŒè¯æ•°æ®åº“è·¯å¾„
        db_path = self.config["database"]["path"]
        if not db_path.exists():
            raise FileNotFoundError(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")

        # åˆ›å»ºè¾“å‡ºç›®å½•
        for path_key in ["output_root", "raw_data_dir", "translated_data_dir", "prompts_dir"]:
            path = self.config["paths"][path_key]
            path.mkdir(parents=True, exist_ok=True)

    def get_ai_config(self) -> Dict[str, Any]:
        """è·å–AIé…ç½®"""
        provider = self.config["ai_config"]["provider"]
        return self.config["ai_config"][provider]

    def get_table_config(self, table_name: str) -> Dict[str, Any]:
        """è·å–è¡¨çš„ç¿»è¯‘é…ç½®"""
        if table_name not in self.config["tables"]:
            raise ValueError(f"æœªçŸ¥çš„è¡¨å: {table_name}")
        return self.config["tables"][table_name]

    def get_prompt_file_path(self, table_name: str) -> Path:
        """è·å–æç¤ºè¯æ–‡ä»¶è·¯å¾„"""
        table_config = self.get_table_config(table_name)
        return self.config["paths"]["prompts_dir"] / table_config["prompt_file"]

    def get_source_file_path(self, table_name: str) -> Path:
        """è·å–æºæ•°æ®æ–‡ä»¶è·¯å¾„"""
        table_config = self.get_table_config(table_name)
        return self.config["paths"]["raw_data_dir"] / table_config["source_file"]

    def get_target_file_path(self, table_name: str) -> Path:
        """è·å–ç›®æ ‡ç¿»è¯‘æ–‡ä»¶è·¯å¾„"""
        table_config = self.get_table_config(table_name)
        return self.config["paths"]["translated_data_dir"] / table_config["target_file"]

    def get_all_table_names(self) -> list:
        """è·å–æ‰€æœ‰éœ€è¦ç¿»è¯‘çš„è¡¨å"""
        return list(self.config["tables"].keys())

    def __getitem__(self, key: str) -> Any:
        """æ”¯æŒå­—å…¸å¼è®¿é—®"""
        return self.config[key]

    def __contains__(self, key: str) -> bool:
        """æ”¯æŒinæ“ä½œç¬¦"""
        return key in self.config


# å…¨å±€é…ç½®å®ä¾‹
_config_instance = None


def get_config() -> TranslationConfig:
    """è·å–å…¨å±€é…ç½®å®ä¾‹"""
    global _config_instance
    if _config_instance is None:
        _config_instance = TranslationConfig()
    return _config_instance


if __name__ == "__main__":
    # é…ç½®éªŒè¯æµ‹è¯•
    try:
        config = get_config()
        print("âœ… ç¿»è¯‘é…ç½®éªŒè¯é€šè¿‡")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {config['paths']['output_root']}")
        print(f"ğŸ—„ï¸ æ•°æ®åº“è·¯å¾„: {config['database']['path']}")
        print(f"ğŸ¤– AIæ¨¡å‹: {config.get_ai_config()['model']}")
        print(f"ğŸ“‹ ç¿»è¯‘è¡¨: {', '.join(config.get_all_table_names())}")
    except Exception as e:
        print(f"âŒ é…ç½®éªŒè¯å¤±è´¥: {e}")
